% Project implementation artifacts
@misc{llamastack,
  title        = {Llama Stack},
  howpublished = {GitHub repository},
  url          = {https://github.com/llamastack/},
  note         = {Accessed: 2026-01-28}
}

@misc{llamastackk8soperator,
  title        = {Llama Stack Kubernetes Operator},
  howpublished = {GitHub repository},
  url          = {https://github.com/llamastack/llama-stack-k8s-operator},
  note         = {Accessed: 2026-01-28}
}

% --- Open-source agentic AI models ---
@misc{openai2025gptoss120bgptoss20bmodel,
  author       = {{OpenAI}},
  title        = {gpt-oss-120b \& gpt-oss-20b Model Card},
  year         = {2025},
  eprint       = {2508.10925},
  archivePrefix= {arXiv},
  primaryClass = {cs.CL},
  url          = {https://arxiv.org/abs/2508.10925}
}

% --- ML lifecycle management ---
@misc{mlflow,
  title        = {{MLflow}: A Machine Learning Lifecycle Platform},
  howpublished = {Open-source project},
  url          = {https://mlflow.org/},
  note         = {Accessed: 2026-02-23}
}

% --- Production ML / ML systems engineering (highly relevant) ---
@inproceedings{sculley2015hiddentechnicaldebt,
  author    = {Sculley, D. and Holt, Gary and Golovin, Daniel and Davydov, Eugene and Phillips, Todd and Ebner, Dietmar and Chaudhary, Vinay and Young, Michael and Crespo, Jean-Fran{\c{c}}ois and Dennison, Dan},
  title     = {Hidden Technical Debt in Machine Learning Systems},
  booktitle = {Advances in Neural Information Processing Systems},
  year      = {2015},
  pages     = {2503--2511},
  url       = {https://proceedings.neurips.cc/paper/2015/hash/86df7dcfd896fcaf2674f757b546b22a-Abstract.html}
}

@inproceedings{amershi2019se4ml,
  author    = {Amershi, Saleema and Begel, Andrew and Bird, Christian and DeLine, Robert and Gall, Harald and Kamar, Ece and Nagappan, Nachiappan and Nushi, Besmira and Zimmermann, Thomas},
  title     = {Software Engineering for Machine Learning: A Case Study},
  booktitle = {Proceedings of the 41st International Conference on Software Engineering: Software Engineering in Practice (ICSE-SEIP)},
  year      = {2019},
  pages     = {291--300},
  doi       = {10.1109/ICSE-SEIP.2019.00042},
  url       = {https://www.microsoft.com/en-us/research/publication/software-engineering-for-machine-learning-a-case-study/}
}

% --- Retrieval / RAG foundations ---
@inproceedings{lewis2020rag,
  author    = {Lewis, Patrick and Perez, Ethan and Piktus, Aleksandra and Petroni, Fabio and Karpukhin, Vladimir and Goyal, Naman and K{\"u}ttler, Heinrich and Lewis, Mike and Yih, Wen{-}tau and Rockt{\"a}schel, Tim and Riedel, Sebastian and Kiela, Douwe},
  title     = {Retrieval-Augmented Generation for Knowledge-Intensive {NLP} Tasks},
  booktitle = {Advances in Neural Information Processing Systems},
  year      = {2020},
  url       = {https://arxiv.org/abs/2005.11401}
}

@inproceedings{karpukhin2020dpr,
  author    = {Karpukhin, Vladimir and Oguz, Barlas and Min, Sewon and Lewis, Patrick and Wu, Ledell and Edunov, Sergey and Chen, Danqi and Yih, Wen{-}tau},
  title     = {Dense Passage Retrieval for Open-Domain Question Answering},
  booktitle = {Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  year      = {2020},
  pages     = {6769--6781},
  doi       = {10.18653/v1/2020.emnlp-main.550},
  url       = {https://aclanthology.org/2020.emnlp-main.550/}
}

@inproceedings{guu2020realm,
  author    = {Guu, Kelvin and Lee, Kenton and Tung, Zora and Pasupat, Panupong and Chang, Ming{-}Wei},
  title     = {{REALM}: Retrieval-Augmented Language Model Pre-Training},
  booktitle = {International Conference on Learning Representations (ICLR)},
  year      = {2020},
  url       = {https://arxiv.org/abs/2002.08909}
}

% --- Vector search / ANN indexing (useful when you discuss similarity search limits) ---
@article{johnson2017faiss,
  author  = {Johnson, Jeff and Douze, Matthijs and J{\'e}gou, Herv{\'e}},
  title   = {Billion-Scale Similarity Search with {GPUs}},
  journal = {arXiv preprint arXiv:1702.08734},
  year    = {2017},
  url     = {https://arxiv.org/abs/1702.08734}
}

% --- Agentic / tool-using LLMs ---
@inproceedings{yao2023react,
  author    = {Yao, Shunyu and Zhao, Jeffrey and Yu, Dian and Du, Nan and Shafran, Izhak and Narasimhan, Karthik and Cao, Yuan},
  title     = {{ReAct}: Synergizing Reasoning and Acting in Language Models},
  booktitle = {International Conference on Learning Representations (ICLR)},
  year      = {2023},
  url       = {https://arxiv.org/abs/2210.03629}
}

@inproceedings{schick2023toolformer,
  author    = {Schick, Timo and Dwivedi{-}Yu, Jane and Dess{\`i}, Roberto and Raileanu, Roberta and Lomeli, Maria and Zettlemoyer, Luke and Cancedda, Nicola and Scialom, Thomas},
  title     = {Toolformer: Language Models Can Teach Themselves to Use Tools},
  booktitle = {International Conference on Learning Representations (ICLR)},
  year      = {2023},
  url       = {https://arxiv.org/abs/2302.04761}
}

% Optional but often useful in a “tool-using agents” related work subsection:
@article{karpas2022mrkl,
  author  = {Karpas, Ehud and Abend, Omri and Belinkov, Yonatan and Lenz, Barak and Lieber, Opher and Ratner, Nir and Shoham, Yoav and Bata, Hofit and Levine, Yoav and Leyton{-}Brown, Kevin and Muhlgay, Dor and Rozen, Noam and Schwartz, Erez and Shachaf, Gal and Shalev{-}Shwartz, Shai and Shashua, Amnon and Tenenholtz, Moshe},
  title   = {{MRKL} Systems: A Modular, Neuro-Symbolic Architecture that Combines Large Language Models, External Knowledge Sources and Discrete Reasoning},
  journal = {arXiv preprint arXiv:2205.00445},
  year    = {2022},
  url     = {https://arxiv.org/abs/2205.00445}
}

% --- LLM serving / shared infrastructure (very relevant to “shared inference” claims) ---
@inproceedings{yu2022orca,
  author    = {Yu, Gyeong{-}In and Jeong, Joo Seong and Kim, Geon{-}Woo and Kim, Soojeong and Chun, Byung{-}Gon},
  title     = {Orca: A Distributed Serving System for Transformer-Based Generative Models},
  booktitle = {16th USENIX Symposium on Operating Systems Design and Implementation (OSDI)},
  year      = {2022},
  pages     = {521--538},
  url       = {https://www.usenix.org/conference/osdi22/presentation/yu}
}

@inproceedings{kwon2023vllm,
  author    = {Kwon, Woosuk and Li, Zhuohan and Zhuang, Siyuan and Sheng, Ying and Zheng, Lianmin and Yu, Cody Hao and Gonzalez, Joseph E. and Zhang, Hao and Stoica, Ion},
  title     = {Efficient Memory Management for Large Language Model Serving with PagedAttention},
  booktitle = {Proceedings of the 29th ACM Symposium on Operating Systems Principles (SOSP)},
  year      = {2023},
  pages     = {611--626},
  doi       = {10.1145/3600006.3613165},
  url       = {https://arxiv.org/abs/2309.06180}
}

% --- Benchmarks (useful if you justify retrieval/embeddings evaluation) ---
@inproceedings{petroni2021kilt,
  author    = {Petroni, Fabio and Piktus, Aleksandra and Fan, Angela and Lewis, Patrick and Yazdani, Majid and {De Cao}, Nicola and Thorne, James and Jernite, Yacine and Karpukhin, Vladimir and Maillard, Jean and others},
  title     = {{KILT}: a Benchmark for Knowledge Intensive Language Tasks},
  booktitle = {Conference of the North American Chapter of the Association for Computational Linguistics (NAACL)},
  year      = {2021},
  url       = {https://aclanthology.org/2021.naacl-main.200/}
}

@article{thakur2021beir,
  author  = {Thakur, Nandan and Reimers, Nils and R{\"u}ckl{\'e}, Andreas and Srivastava, Abhishek and Gurevych, Iryna},
  title   = {{BEIR}: A Heterogeneous Benchmark for Zero-shot Evaluation of Information Retrieval Models},
  journal = {arXiv preprint arXiv:2104.08663},
  year    = {2021},
  url     = {https://arxiv.org/abs/2104.08663}
}

@article{muennighoff2022mteb,
  author  = {Muennighoff, Niklas and Tazi, Nouamane and Magne, Lo{\"i}c and Reimers, Nils},
  title   = {{MTEB}: Massive Text Embedding Benchmark},
  journal = {arXiv preprint arXiv:2210.07316},
  year    = {2022},
  url     = {https://arxiv.org/abs/2210.07316}
}

% --- Citation-aware generation (optional, if you discuss evidence admission / citations) ---
@inproceedings{gao2023alce,
  author    = {Gao, Tianyu and Yen, Howard and Yu, Jiatong and Chen, Danqi},
  title     = {Enabling Large Language Models to Generate Text with Citations},
  booktitle = {Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  year      = {2023},
  url       = {https://arxiv.org/abs/2305.14627}
}

% --- Agent evaluation / real-world tasks (optional) ---
@inproceedings{jimenez2024swebench,
  author    = {Jimenez, Carlos E. and Yang, John and Wettig, Alexander and Yao, Shunyu and Pei, Kexin and Press, Ofir and Narasimhan, Karthik},
  title     = {{SWE}-bench: Can Language Models Resolve Real-World {GitHub} Issues?},
  booktitle = {International Conference on Learning Representations (ICLR)},
  year      = {2024},
  url       = {https://arxiv.org/abs/2310.06770}
}

% --- Kubernetes / shared cluster substrate (useful if you motivate k8s operator + multitenancy) ---
@article{burns2016borg,
  author  = {Burns, Brendan and Grant, Brian and Oppenheimer, David and Brewer, Eric and Wilkes, John},
  title   = {Borg, Omega, and Kubernetes},
  journal = {Communications of the ACM},
  year    = {2016},
  url     = {https://cacm.acm.org/practice/borg-omega-and-kubernetes/}
}

% --- API paradigm reference (cite as documentation/spec) ---
@misc{openaiResponsesAPI,
  author       = {{OpenAI}},
  title        = {Responses {API} Reference},
  howpublished = {Online documentation},
  url          = {https://platform.openai.com/docs/api-reference/responses},
  note         = {Accessed: 2026-02-16}
}
